{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import sys\n",
    "from lxml import etree\n",
    "sys.path.insert(0, '../notebooks/libs/')\n",
    "import FeatureExtraction as FE\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathToFile='../../dataset/training/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml'\n",
    "tree=etree.parse(pathToFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ovo nije potrebno\n",
    "def generator_author_and_conversation(dictionary):\n",
    "    for key in dictionary:\n",
    "        data = [dictionary.get(key)]\n",
    "        data.insert(0,key)\n",
    "        yield data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_words_from_dictionary(dictionary):\n",
    "    regex1 = re.compile(r'(.)\\1{5,}')\n",
    "    regex2 = re.compile(r'^[0-9]*$')\n",
    "    for key in dictionary:\n",
    "        text = dictionary.get(key)\n",
    "        if None in text:\n",
    "            continue\n",
    "        text = [x for x in text if len(x)<20]\n",
    "        text = [i for i in text if not regex1.search(i)]\n",
    "        text = [i for i in text if not regex2.search(i)]\n",
    "        dictionary[key] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function returns author - term matrix \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def make_tf_idf_matrix_from_XML(pathToFile):\n",
    "    tree=etree.parse(pathToFile)\n",
    "    message_node = FE.extract_message_nodes_as_list_from_parsed_text(tree)\n",
    "    dictionary= FE.extract_author_text_dictionary_from_message_nodes(message_node)\n",
    "    list_of_authors_strings = []\n",
    "    for key in dictionary:\n",
    "        tmp = dictionary.get(key)\n",
    "        if None in tmp:\n",
    "            continue\n",
    "        list_of_authors_strings.append(' '.join(dictionary.get(key)))\n",
    "    tfidf=TfidfVectorizer(stop_words='english',min_df=10)\n",
    "    #X = tfidf.fit_transform(list_of_authors_strings)\n",
    "    #idf = tfidf._tfidf\n",
    "    return tfidf.fit_transform(list_of_authors_strings), tfidf.get_feature_names(), list(dictionary.keys())\n",
    "    #return dict(zip(tfidf.get_feature_names(), idf))\n",
    "    #return tfidf.get_feature_names(),idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_for_tf_idf(path_to_dataset_xml):\n",
    "    tree=etree.parse(path_to_dataset_xml)\n",
    "    message_node = extract_message_nodes_as_list_from_parsed_text(tree)\n",
    "    dictionary= extract_author_text_dictionary_from_message_nodes(message_node)\n",
    "    filter_words_from_dictionary(dictionary) \n",
    "    list_of_authors_strings = []\n",
    "    for key in sorted(dictionary):\n",
    "        tmp = dictionary.get(key)\n",
    "        if None in tmp:\n",
    "            dictionary[key]=''\n",
    "        list_of_authors_strings.append(' '.join(dictionary.get(key)))\n",
    "    return list_of_authors_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function returns author - term matrix \n",
    "def make_tf_idf_matrix_from_XML(path_to_training, path_to_test):\n",
    "    tree=etree.parse(path_to_training)\n",
    "    message_node = extract_message_nodes_as_list_from_parsed_text(tree)\n",
    "    dictionary= extract_author_text_dictionary_from_message_nodes(message_node)\n",
    "    filter_words_from_dictionary(dictionary)\n",
    "    \n",
    "    list_of_authors_strings_training = []\n",
    "    for key in dictionary:\n",
    "        tmp = dictionary.get(key)\n",
    "        if None in tmp:\n",
    "            dictionary[key]=''\n",
    "            \n",
    "        list_of_authors_strings_training.append(' '.join(dictionary.get(key)))\n",
    "    \n",
    "    tree=etree.parse(path_to_test)\n",
    "    message_node = extract_message_nodes_as_list_from_parsed_text(tree)\n",
    "    dictionary= extract_author_text_dictionary_from_message_nodes(message_node)\n",
    "    filter_words_from_dictionary(dictionary)\n",
    "    \n",
    "    list_of_authors_strings_test = []\n",
    "    for key in dictionary:\n",
    "        tmp = dictionary.get(key)\n",
    "        if None in tmp:\n",
    "            dictionary[key]=''\n",
    "            \n",
    "        list_of_authors_strings_test.append(' '.join(dictionary.get(key)))\n",
    "        \n",
    "    tfidf=TfidfVectorizer(stop_words='english',min_df=10)\n",
    "    \n",
    "    return tfidf.fit_transform(list_of_authors_strings_training), tfidf.transform(list_of_authors_strings_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "make_tf_idf_matrix_from_XML() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-aac0f13d9000>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmake_tf_idf_matrix_from_XML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: make_tf_idf_matrix_from_XML() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "make_tf_idf_matrix_from_XML(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = {\"ana\" : [\"sibenik\",\"zagreb\"], \"petra\":[\"makarska\",\"zagreb\",\"blaaaaaaaaaaaaaaaaaaaaaaaaaa\"],\"vinko\":[\"nestttttto\",\"blaaa\",\"099911\",\"007\"] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vinko': ['blaaa'], 'ana': ['sibenik', 'zagreb'], 'petra': ['makarska', 'zagreb']}\n"
     ]
    }
   ],
   "source": [
    "filter_words_from_dictionary(a)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot parse from 'lxml.etree._ElementTree'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ffd700aa538a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mauthors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_tf_idf_matrix_from_XML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-39264fd36f9c>\u001b[0m in \u001b[0;36mmake_tf_idf_matrix_from_XML\u001b[1;34m(pathToFile)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_tf_idf_matrix_from_XML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathToFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0metree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathToFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmessage_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_message_nodes_as_list_from_parsed_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mFE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_author_text_dictionary_from_message_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\lxml.etree.pyx\u001b[0m in \u001b[0;36mlxml.etree.parse (src\\lxml\\lxml.etree.c:80041)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocument (src\\lxml\\lxml.etree.c:116533)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot parse from 'lxml.etree._ElementTree'"
     ]
    }
   ],
   "source": [
    "matrix,names,authors = make_tf_idf_matrix_from_XML(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n"
     ]
    }
   ],
   "source": [
    "#fo = open(\"tf_idf.csv\",\"w\")\n",
    "\n",
    "#row = matrix.shape[0]\n",
    "row = 100\n",
    "col = matrix.shape[1]\n",
    "#col = 100\n",
    "lines = []\n",
    "big_lines=[]\n",
    "#buff_cnt = 0\n",
    "with open('tf_idf_test.csv',\"w+\") as fo:\n",
    "    a = [\"author_ID\"]\n",
    "    for i in range(0,col):\n",
    "        a.append(names[i].encode(\"utf-8\"))\n",
    "    fo.write(','.join(a) + '\\n')\n",
    "\n",
    "    for i in range(0, row):\n",
    "        lines.append(authors[i])\n",
    "        matrix[i:]\n",
    "        for j in range(0,col):\n",
    "            lines.append(matrix[i,j])\n",
    "            \n",
    "        big_lines.append(','.join(map(str, lines))+'\\n') #print lines[i]\n",
    "        lines=[]\n",
    "        if len(big_lines)==10:\n",
    "            print \"deset\"\n",
    "            #print len(big_lines)\n",
    "            #print lines[0]\n",
    "            for line in big_lines:\n",
    "                fo.write(line)\n",
    "            big_lines=[]\n",
    "        elif i == (col-1):\n",
    "            for line in big_lines:\n",
    "                fo.write(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deset somova\n",
      "deset somova\n",
      "deset somova\n",
      "deset somova\n",
      "deset somova\n",
      "deset somova\n",
      "deset somova\n",
      "deset somova\n",
      "deset somova\n"
     ]
    }
   ],
   "source": [
    "row = matrix.shape[0]\n",
    "#row = 1000\n",
    "col = matrix.shape[1]\n",
    "#col = 100\n",
    "lines = []\n",
    "big_lines=[]\n",
    "#buff_cnt = 0\n",
    "str_buff = \"\"\n",
    "with open('tf_idf_test.csv',\"w+\") as fo:\n",
    "    a = [\"author_ID\"]\n",
    "    for i in range(0,col):\n",
    "        a.append(names[i].encode(\"utf-8\"))\n",
    "    fo.write(','.join(a) + '\\n')\n",
    "\n",
    "    for i in range(0, row):\n",
    "        str_buff = authors[i]+','\n",
    "        mat = np.ravel(matrix[i].todense())\n",
    "        mat = [str(x) for x in mat]\n",
    "        str_buff+=(','.join(mat)+'\\n')\n",
    "        big_lines.append(str_buff) #print lines[i]\n",
    "        str_buff=\"\"\n",
    "        if len(big_lines)==10000:\n",
    "            print \"deset somova\"\n",
    "            for line in big_lines:\n",
    "                fo.write(line)\n",
    "            big_lines=[]\n",
    "        elif i == (row-1):\n",
    "            for line in big_lines:\n",
    "                fo.write(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97377, 3083)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = matrix[18].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ravelana = np.ravel(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print str(ravelana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ravelana = [str(x) for x in ravelana]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fajl = pd.read_csv(\"tf_idf_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97377, 3084)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fajl.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
