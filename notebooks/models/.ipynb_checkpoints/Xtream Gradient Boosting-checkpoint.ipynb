{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import itertools\n",
    "import sklearn.metrics as met\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy as sp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../notebooks/libs/')\n",
    "import FeatureExtraction as FE\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv('../../csv/chat_based_features_training.csv')\n",
    "test = pd.read_csv('../../csv/chat_based_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filtering chat based\n",
    "#minimal_number_of_messages_treshold = 2\n",
    "#training = training[training['number of messages sent'] >= minimal_number_of_messages_treshold]\n",
    "#test = test[test['number of messages sent'] >= minimal_number_of_messages_treshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['number of conversation', 'percent of conversations started by the author', 'number of messages sent', 'average percent of lines in conversation', 'number of characters sent by the author']\n",
    "\n",
    "important_features = ['percent of conversations started by the author',\n",
    "                      'difference between two preceding lines in seconds', 'number of messages sent',\n",
    "                      'average percent of lines in conversation', \n",
    "                      \n",
    "                      'number of characters sent by the author', 'mean time of messages sent',\n",
    "                      \n",
    "                      'avg number of unique authors interacted with per conversation', \n",
    "                      'total unique authors and unique per chat difference',\n",
    "                \n",
    "                      'total question marks',\n",
    "                      'total author question marks', 'avg author question marks',\n",
    "                      'author and conversation quetsion mark differnece', 'pos word count author',\n",
    "                      'prof word count author']\n",
    "#training_sparse = sp.sparse.csr_matrix(training[features].ix[:,1:].values, dtype=float)[:,:-1]\n",
    "#test_sparse = sp.sparse.csr_matrix(test[features].ix[:,1:].values, dtype=float)[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_xml = '../../dataset/training/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml'\n",
    "test_xml = '../../dataset/test/pan12-sexual-predator-identification-test-corpus-2012-05-17.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filtering TF-IDF\n",
    "# Original documents_training = FE.prepare_for_tf_idf(training_xml, False)\n",
    "\n",
    "documents_training = FE.prepare_for_tf_idf(training_xml, False)\n",
    "documents_test = FE.prepare_for_tf_idf(test_xml, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(stop_words='english', min_df=3, max_features=2500) #max_features=2500\n",
    "matrix_training=tfidf.fit_transform(documents_training)\n",
    "matrix_testing=tfidf.transform(documents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print matrix_training.shape\n",
    "#print training_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number of conversation', 'percent of conversations started by the author', 'difference between two preceding lines in seconds', 'number of messages sent', 'average percent of lines in conversation', 'average percent of characters in conversation', 'number of characters sent by the author', 'mean time of messages sent', 'number of unique contacted authors', 'avg number of unique authors interacted with per conversation', 'total unique authors and unique per chat difference', 'conversation num and total unique authors difference', 'average question marks per conversations', 'total question marks', 'total author question marks', 'avg author question marks', 'author and conversation quetsion mark differnece', 'author total negative in author conv', 'author total neutral in author conv', 'author total positive in author conv', ' authortotal compound in author conv', 'pos word count author', 'neg word count author', 'prof word count author']\n"
     ]
    }
   ],
   "source": [
    "column_names = training.columns.values.tolist()[1:-1]\n",
    "print column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_all = sp.sparse.hstack((training[column_names], matrix_training))\n",
    "test_all = sp.sparse.hstack((test[column_names], matrix_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler(with_mean=False)\n",
    "training_all=scaler.fit_transform(training_all)\n",
    "test_all=scaler.transform(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training_all = normalize(training_all, norm='l1', axis=1)\n",
    "#test_all = normalize(test_all, norm='l1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0.4, learning_rate=0.3, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=0, missing=None, n_estimators=177, nthread=8,\n",
       "       objective='binary:logistic', reg_alpha=1e-07, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL DOBIVEN PARAMETER TUNINONG NA TRAINING SETU (grid search i cross validation)\n",
    "\n",
    "model = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=27, reg_alpha= 1e-07)\n",
    "\n",
    "model.fit(training_all, training[['is sexual predator']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.999401011422\n",
      "Precision:  0.896774193548\n",
      "Recall: 0.547244094488\n",
      "F1: 0.679706601467\n",
      "F0.5: 0.795194508009\n"
     ]
    }
   ],
   "source": [
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], prediction) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], prediction)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], prediction)\n",
    "print 'F1:', met.f1_score(test[['is sexual predator']], prediction)\n",
    "print 'F0.5:', met.fbeta_score(test[['is sexual predator']], prediction, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=27, reg_alpha= 1e-07)\n",
    "\n",
    "model2 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=1, reg_alpha= 1e-07)\n",
    "\n",
    "model3 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=53, reg_alpha= 1e-07)\n",
    "\n",
    "model4 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=97, reg_alpha= 1e-07)\n",
    "\n",
    "model5 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=171, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=127, reg_alpha= 1e-07)\n",
    "\n",
    "model6 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=227, reg_alpha= 1e-07)\n",
    "\n",
    "model7 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=292, reg_alpha= 1e-07)\n",
    "\n",
    "model8 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=353, reg_alpha= 1e-07)\n",
    "\n",
    "model9 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=455, reg_alpha= 1e-07)\n",
    "\n",
    "model10 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=523, reg_alpha= 1e-07)\n",
    "\n",
    "model1.fit(training_all, training[['is sexual predator']])\n",
    "model2.fit(training_all, training[['is sexual predator']])\n",
    "model3.fit(training_all, training[['is sexual predator']])\n",
    "model4.fit(training_all, training[['is sexual predator']])\n",
    "model5.fit(training_all, training[['is sexual predator']])\n",
    "model6.fit(training_all, training[['is sexual predator']])\n",
    "model7.fit(training_all, training[['is sexual predator']])\n",
    "model8.fit(training_all, training[['is sexual predator']])\n",
    "model9.fit(training_all, training[['is sexual predator']])\n",
    "model10.fit(training_all, training[['is sexual predator']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction1 = model1.predict(test_all)\n",
    "prediction2 = model2.predict(test_all)\n",
    "prediction3 = model3.predict(test_all)\n",
    "prediction4 = model4.predict(test_all)\n",
    "prediction5 = model5.predict(test_all)\n",
    "prediction6 = model6.predict(test_all)\n",
    "prediction7 = model7.predict(test_all)\n",
    "prediction8 = model8.predict(test_all)\n",
    "prediction9 = model9.predict(test_all)\n",
    "prediction10 = model10.predict(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = bagging(2, [prediction1, prediction2, prediction3, prediction4, prediction5,\n",
    "                        prediction6, prediction7, prediction8, prediction9, prediction10])\n",
    "\n",
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], prediction) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], prediction)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], prediction)\n",
    "print 'F1:', met.fbeta_score(test[['is sexual predator']], prediction, 1)\n",
    "print 'F0.5:', met.fbeta_score(test[['is sexual predator']], prediction, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_names = training.columns.values.tolist()[1:-1]\n",
    "print column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove scale_post_weight -> smaller F1 score, lower recall but increase precision\n",
    "# Remove gama for bigger precision\n",
    "sex_offender0 = xgb.XGBClassifier(max_depth=13, n_estimators=280, learning_rate=0.028, scale_pos_weight=5, gamma=4,\n",
    "                          min_child_weight=5, subsample=1, max_delta_step=3)\n",
    "sex_offender1 = xgb.XGBClassifier(max_depth=25, n_estimators=300)\n",
    "sex_offender2 = xgb.XGBClassifier(max_depth=5, n_estimators=220, learning_rate=0.007, scale_pos_weight=20, gamma=2)\n",
    "sex_offender3 = xgb.XGBClassifier(max_depth=3, n_estimators=400)\n",
    "sex_offender4 = xgb.XGBClassifier(max_depth=7, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sex_offender0.fit(training_all, training[['is sexual predator']])\n",
    "sex_offender1.fit(training_all, training[['is sexual predator']])\n",
    "sex_offender2.fit(training_all, training[['is sexual predator']])\n",
    "sex_offender3.fit(training_all, training[['is sexual predator']])\n",
    "sex_offender4.fit(training_all, training[['is sexual predator']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction0 = sex_offender0.predict(test_all)\n",
    "prediction1 = sex_offender1.predict(test_all)\n",
    "prediction2 = sex_offender2.predict(test_all)\n",
    "prediction3 = sex_offender3.predict(test_all)\n",
    "prediction4 = sex_offender4.predict(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bagging(vote_number, prediction_list):\n",
    "    total_prediction = []\n",
    "    for i in range(len(prediction_list[0])):\n",
    "        voters = 0\n",
    "        \n",
    "        for prediction in prediction_list:\n",
    "            if prediction[i] == 1:\n",
    "                voters += 1\n",
    "                \n",
    "        if voters >= vote_number:\n",
    "            total_prediction.append(1)\n",
    "        else:\n",
    "            total_prediction.append(0)\n",
    "                \n",
    "    return np.array(total_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = bagging(5, [prediction0, prediction1, prediction2, prediction3, prediction4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], prediction) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], prediction)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], prediction)\n",
    "print 'F1:', met.fbeta_score(test[['is sexual predator']], prediction, 1)\n",
    "print 'F0.5:', met.fbeta_score(test[['is sexual predator']], prediction, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "max_f1 = 0\n",
    "best_features = []\n",
    "\n",
    "for num_features in range(2, len(column_names)-1):\n",
    "    for column_name_subset in itertools.combinations(column_names, num_features):\n",
    "\n",
    "        forest = forest.fit(training[list(column_name_subset)], np.ravel(training.iloc[:,[9]]))\n",
    "        prediction = forest.predict(test[list(column_name_subset)])\n",
    "\n",
    "        print column_name_subset\n",
    "        print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], prediction) \n",
    "        print 'Precision: ', met.precision_score(test[['is sexual predator']], prediction)\n",
    "        print 'Recall:', met.recall_score(test[['is sexual predator']], prediction)\n",
    "        print 'F1:', met.f1_score(test[['is sexual predator']], prediction)\n",
    "        print \"\\n\\n\"\n",
    "\n",
    "        f1 = met.f1_score(test[['is sexual predator']], prediction)\n",
    "        if max_f1 < f1:\n",
    "            max_f1 = f1\n",
    "            best_features =  column_name_subset\n",
    "                                                                                                 \n",
    "print max_f1\n",
    "print best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "def ceate_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    i = 0\n",
    "    for feat in features:\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "        i = i + 1\n",
    "\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "features = training.columns.values.tolist()[1:-1]\n",
    "x_train = training_all\n",
    "y_train = training['is sexual predator']\n",
    "ceate_feature_map(features)\n",
    "\n",
    "xgb_params = {\"objective\": \"binary:logistic\", \"eta\": 0.28, \"max_depth\": 13, \"seed\": 42, \"silent\": 1,\n",
    "             \"n_estimators\": 280, \"gamma\":4, \"min_child_weight\":5, \"scale_pos_weight\":5}\n",
    "num_rounds = 1000\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "gbdt = xgb.train(xgb_params, dtrain, num_rounds)\n",
    "\n",
    "importance = gbdt.get_fscore(fmap='xgb.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "\n",
    "plt.figure()\n",
    "df.plot()\n",
    "df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "plt.gcf().savefig('feature_importance_xgb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(test_all, label=test['is sexual predator'])\n",
    "#gbdt.fit(dtest[predictors], dtest['is sexual preadtor'],eval_metric='auc')\n",
    "prediction = gbdt.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(gbdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.to_graphviz(gbdt, num_trees=2)\n",
    "#print prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], prediction) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], prediction)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], prediction)\n",
    "print 'F1:', met.fbeta_score(test[['is sexual predator']], prediction, 1)\n",
    "print 'F0.5:', met.fbeta_score(test[['is sexual predator']], prediction, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "target = 'is sexual predator'\n",
    "\n",
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['is sexual preadtor'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['is sexual preadtor'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['is sexual preadtor'], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = training.columns.values.tolist()[1:-1]\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, training, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
