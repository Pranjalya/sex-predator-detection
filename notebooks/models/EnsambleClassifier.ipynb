{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sklearn.metrics as met\n",
    "import scipy as sp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../notebooks/libs/')\n",
    "import FeatureExtraction as FE\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "import sklearn.metrics as met\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv('../../csv/chat_based_features_training.csv')\n",
    "test = pd.read_csv('../../csv/chat_based_features_test.csv')\n",
    "\n",
    "features = ['number of conversation', 'percent of conversations started by the author', 'number of messages sent',\n",
    "            'average percent of lines in conversation', 'number of characters sent by the author']\n",
    "\n",
    "column_names = training.columns.values.tolist()[1:-1]\n",
    "\n",
    "training_sparse_chat_based = sp.sparse.csr_matrix(training[column_names].values, dtype=float)\n",
    "test_sparse_chat_based = sp.sparse.csr_matrix(test[column_names].values, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_xml = '../../dataset/training/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml'\n",
    "test_xml = '../../dataset/test/pan12-sexual-predator-identification-test-corpus-2012-05-17.xml'\n",
    "\n",
    "documents_training = FE.prepare_for_tf_idf(training_xml, False)\n",
    "documents_test = FE.prepare_for_tf_idf(test_xml, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', min_df=3, max_features=2500)\n",
    "\n",
    "training_sparse_tfidf = tfidf.fit_transform(documents_training)\n",
    "testing_sparse_tfidf = tfidf.transform(documents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_all = sp.sparse.hstack((training_sparse_tfidf, training_sparse_chat_based))\n",
    "\n",
    "test_all = sp.sparse.hstack((testing_sparse_tfidf, test_sparse_chat_based))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler(with_mean=False)\n",
    "training_all=scaler.fit_transform(training_all)\n",
    "test_all=scaler.transform(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0.4, learning_rate=0.3, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=0, missing=None, n_estimators=177, nthread=8,\n",
       "       objective='binary:logistic', reg_alpha=1e-07, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=27, reg_alpha= 1e-07)\n",
    "\n",
    "model.fit(training_all, training[['is sexual predator']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_xgb = model.predict(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.999414728718\n",
      "Precision:  0.875\n",
      "Recall: 0.57874015748\n",
      "F1: 0.696682464455\n",
      "F0.5: 0.79373650108\n"
     ]
    }
   ],
   "source": [
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], prediction_xgb) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], prediction_xgb)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], prediction_xgb)\n",
    "print 'F1:', met.f1_score(test[['is sexual predator']], prediction_xgb)\n",
    "print 'F0.5:', met.fbeta_score(test[['is sexual predator']], prediction_xgb, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chat_based_scaled_and_tfidf_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c4be3a283293>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mxgb_all_5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mxgb_all_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchat_based_scaled_and_tfidf_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is sexual predator'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mxgb_all_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchat_based_scaled_and_tfidf_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is sexual predator'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mxgb_all_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchat_based_scaled_and_tfidf_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is sexual predator'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chat_based_scaled_and_tfidf_training' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_all_1 = xgb.XGBClassifier(max_depth=13, n_estimators=280, learning_rate=0.028, scale_pos_weight=5, gamma=4,\n",
    "                          min_child_weight=5, subsample=1, max_delta_step=3)\n",
    "xgb_all_2 = xgb.XGBClassifier(max_depth=25, n_estimators=300)\n",
    "xgb_all_3 = xgb.XGBClassifier(max_depth=5, n_estimators=220, learning_rate=0.007, scale_pos_weight=20, gamma=2)\n",
    "xgb_all_4 = xgb.XGBClassifier(max_depth=3, n_estimators=400)\n",
    "xgb_all_5 = xgb.XGBClassifier(max_depth=7, n_estimators=100)\n",
    "\n",
    "xgb_all_1.fit(chat_based_scaled_and_tfidf_training, training[['is sexual predator']])\n",
    "xgb_all_2.fit(chat_based_scaled_and_tfidf_training, training[['is sexual predator']])\n",
    "xgb_all_3.fit(chat_based_scaled_and_tfidf_training, training[['is sexual predator']])\n",
    "xgb_all_4.fit(chat_based_scaled_and_tfidf_training, training[['is sexual predator']])\n",
    "xgb_all_5.fit(chat_based_scaled_and_tfidf_training, training[['is sexual predator']])\n",
    "\n",
    "prediction0 = xgb_all_1.predict(chat_based_scaled_and_tfidf_test)\n",
    "prediction1 = xgb_all_2.predict(chat_based_scaled_and_tfidf_test)\n",
    "prediction2 = xgb_all_3.predict(chat_based_scaled_and_tfidf_test)\n",
    "prediction3 = xgb_all_4.predict(chat_based_scaled_and_tfidf_test)\n",
    "prediction4 = xgb_all_5.predict(chat_based_scaled_and_tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bagging(vote_number, prediction_list):\n",
    "    total_prediction = []\n",
    "    for i in range(len(prediction_list[0])):\n",
    "        voters = 0\n",
    "        \n",
    "        for prediction in prediction_list:\n",
    "            if prediction[i] == 1:\n",
    "                voters += 1\n",
    "                \n",
    "        if voters >= vote_number:\n",
    "            total_prediction.append(1)\n",
    "        else:\n",
    "            total_prediction.append(0)\n",
    "                \n",
    "    return np.array(total_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_all_prediction_bagged = bagging(4, [prediction0, prediction1, prediction2, prediction3, prediction4])\n",
    "\n",
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], xgb_all_prediction_bagged) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], xgb_all_prediction_bagged)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], xgb_all_prediction_bagged)\n",
    "print 'F1:', met.fbeta_score(test[['is sexual predator']], xgb_all_prediction_bagged, 1)\n",
    "print 'F0.5:', met.fbeta_score(test[['is sexual predator']], xgb_all_prediction_bagged, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0.4, learning_rate=0.3, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=0, missing=None, n_estimators=177, nthread=8,\n",
       "       objective='binary:logistic', reg_alpha=1e-07, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=5323, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=27, reg_alpha= 1e-07)\n",
    "\n",
    "model2 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=1, reg_alpha= 1e-07)\n",
    "\n",
    "model3 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=53, reg_alpha= 1e-07)\n",
    "\n",
    "model4 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=97, reg_alpha= 1e-07)\n",
    "\n",
    "model5 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=171, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=1127, reg_alpha= 1e-07)\n",
    "\n",
    "model6 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=22227, reg_alpha= 1e-07)\n",
    "\n",
    "model7 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=24392, reg_alpha= 1e-07)\n",
    "\n",
    "model8 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=353, reg_alpha= 1e-07)\n",
    "\n",
    "model9 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=41255, reg_alpha= 1e-07)\n",
    "\n",
    "model10 = xgb.XGBClassifier( learning_rate = 0.3, n_estimators=177, max_depth=4,\n",
    " min_child_weight=0, gamma=0.4, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=8, scale_pos_weight=1,seed=5323, reg_alpha= 1e-07)\n",
    "\n",
    "model1.fit(training_all, training[['is sexual predator']])\n",
    "model2.fit(training_all, training[['is sexual predator']])\n",
    "model3.fit(training_all, training[['is sexual predator']])\n",
    "model4.fit(training_all, training[['is sexual predator']])\n",
    "model5.fit(training_all, training[['is sexual predator']])\n",
    "model6.fit(training_all, training[['is sexual predator']])\n",
    "model7.fit(training_all, training[['is sexual predator']])\n",
    "model8.fit(training_all, training[['is sexual predator']])\n",
    "model9.fit(training_all, training[['is sexual predator']])\n",
    "model10.fit(training_all, training[['is sexual predator']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction1 = model1.predict(test_all)\n",
    "prediction2 = model2.predict(test_all)\n",
    "prediction3 = model3.predict(test_all)\n",
    "prediction4 = model4.predict(test_all)\n",
    "prediction5 = model5.predict(test_all)\n",
    "prediction6 = model6.predict(test_all)\n",
    "prediction7 = model7.predict(test_all)\n",
    "prediction8 = model8.predict(test_all)\n",
    "prediction9 = model9.predict(test_all)\n",
    "prediction10 = model10.predict(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.999465025468\n",
      "Precision:  0.854922279793\n",
      "Recall: 0.649606299213\n",
      "F1: 0.738255033557\n",
      "F0.5: 0.804093567251\n"
     ]
    }
   ],
   "source": [
    "prediction_10_xgb = bagging(2, [prediction1, prediction2, prediction3, prediction4, prediction5,\n",
    "                        prediction6, prediction7, prediction8, prediction9, prediction10])\n",
    "\n",
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], prediction_10_xgb) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], prediction_10_xgb)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], prediction_10_xgb)\n",
    "print 'F1:', met.fbeta_score(test[['is sexual predator']], prediction_10_xgb, 1)\n",
    "print 'F0.5:', met.fbeta_score(test[['is sexual predator']], prediction_10_xgb, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.7454, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=100, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_all = RandomForestClassifier(n_estimators=230, n_jobs=8, bootstrap=False)\n",
    "rf_all = rf_all.fit(training_all, np.ravel(training[['is sexual predator']]))\n",
    "\n",
    "xgb_all = xgb.XGBClassifier(max_depth=14, n_estimators=300, learning_rate=0.2, scale_pos_weight=5, gamma=4,\n",
    "                          min_child_weight=5, subsample=1)\n",
    "xgb_all.fit(training_all, np.ravel(training[['is sexual predator']]))\n",
    "\n",
    "xgb_chat_based = xgb.XGBClassifier(max_depth=25, n_estimators=300, learning_rate=0.007, scale_pos_weight=5,\n",
    "                                   gamma=7, objective='binary:logistic')\n",
    "xgb_chat_based.fit(training_all, np.ravel(training[['is sexual predator']]))\n",
    "\n",
    "svm_tfidf = svm.SVC(C=0.35,kernel='linear',max_iter=100)\n",
    "svm_tfidf.fit(training_sparse_tfidf, np.ravel(training[['is sexual predator']]))\n",
    "\n",
    "svm_chat_based = svm.SVC(C=0.7454,kernel='linear',max_iter=100)\n",
    "svm_chat_based.fit(training_sparse_chat_based, np.ravel(training[['is sexual predator']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_all_predicition = rf_all.predict(test_all)\n",
    "xgb_all_prediction = xgb_all.predict(test_all)\n",
    "xgb_chat_based_prediction = xgb_chat_based.predict(test_all)\n",
    "svm_tfidf_predicition  = svm_tfidf.predict(testing_sparse_tfidf)\n",
    "svm_cb_predicition  = svm_chat_based.predict(test_sparse_chat_based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_file_prediction(path):\n",
    "    f = open(path, 'r')\n",
    "    return f.read().split(' ')\n",
    "\n",
    "petra_svm_pred = get_file_prediction('predicted_svm.txt')\n",
    "print len(petra_svm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensamble_prediction = bagging(4, [xgb_all_prediction, xgb_chat_based_prediction, prediction_xgb,\n",
    "                                  rf_all_predicition, svm_tfidf_predicition, svm_cb_predicition,\n",
    "                                 prediction_10_xgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.999465025468\n",
      "Precision:  0.910179640719\n",
      "Recall: 0.59842519685\n",
      "F1: 0.722090261283\n",
      "F0.5: 0.824295010846\n"
     ]
    }
   ],
   "source": [
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], ensamble_prediction) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], ensamble_prediction)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], ensamble_prediction)\n",
    "print 'F1:', met.fbeta_score(test[['is sexual predator']], ensamble_prediction, 1)\n",
    "print 'F0.5:', met.fbeta_score(test[['is sexual predator']], ensamble_prediction, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_predators_to_file(prediction, authors):\n",
    "    output_handle = open('classified_preadtors_822.txt', 'w')\n",
    "    bool_list = [True if p == 1 else False for p in prediction]\n",
    "    predators = authors[bool_list]\n",
    "    for predator in predators:\n",
    "        output_handle.write(predator + '\\n')\n",
    "        \n",
    "write_predators_to_file(ensamble_prediction, test['autor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = {'p1':svm_tfidf_predicition, 'p2':rf_chat_based_predicition, 'p3':xgb_all_prediction_bagged,\n",
    "#        'p4':xgb_all_prediction, 'p5':xgb_chat_based_prediction}\n",
    "#s = pd.DataFrame(data)\n",
    "\n",
    "#s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf1 = xgb.XGBClassifier(max_depth=14, n_estimators=300, learning_rate=0.2, scale_pos_weight=5, gamma=4,\n",
    "                          min_child_weight=5, subsample=1)\n",
    "clf2 = svm.SVC(C=0.35,kernel='linear',max_iter=100)\n",
    "clf3 = RandomForestClassifier(n_estimators=230, n_jobs=8, bootstrap=False)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('xgb', clf1), ('svm', clf2), ('rf', clf3)],\n",
    "                        weights=[1, 1, 1])\n",
    "\n",
    "\n",
    "features = ['number of conversation', 'percent of conversations started by the author', 'number of messages sent', 'average percent of lines in conversation', 'number of characters sent by the author']\n",
    "\n",
    "clf1 = clf1.fit(chat_based_scaled_and_tfidf_training, np.ravel(training[['is sexual predator']]))\n",
    "clf2 = clf2.fit(training[features], np.ravel(training[['is sexual predator']]))\n",
    "clf3 = clf3.fit(training[features], np.ravel(training[['is sexual predator']]))\n",
    "\n",
    "eclf = eclf.fit(training[features], np.ravel(training[['is sexual predator']]))\n",
    "\n",
    "eclf_prediction = eclf.predict(test[features])\n",
    "\n",
    "\n",
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], eclf_prediction) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], eclf_prediction)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], eclf_prediction)\n",
    "print 'F1:', met.fbeta_score(test[['is sexual predator']], eclf_prediction, 1)\n",
    "print 'F0.5:', met.fbeta_score(test[['is sexual predator']], eclf_prediction, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = DecisionTreeClassifier(max_depth=4)\n",
    "clf5 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf6 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gn', clf3),\n",
    "        ('dt', clf4), ('knn', clf5), ('svc', clf6)], voting='soft', weights=[1,1,1,2,1,2])\n",
    "\n",
    "features = ['number of conversation', 'percent of conversations started by the author', 'number of messages sent', 'average percent of lines in conversation', 'number of characters sent by the author']\n",
    "clf1 = clf1.fit(training[features], np.ravel(training[['is sexual predator']]))\n",
    "clf2 = clf2.fit(training[features], np.ravel(training[['is sexual predator']]))\n",
    "clf3 = clf3.fit(training[features], np.ravel(training[['is sexual predator']]))\n",
    "clf4 = clf4.fit(training[features], np.ravel(training[['is sexual predator']]))\n",
    "clf5 = clf5.fit(training[features], np.ravel(training[['is sexual predator']]))\n",
    "clf6 = clf6.fit(training[features], np.ravel(training[['is sexual predator']]))\n",
    "eclf = eclf.fit(training[features], np.ravel(training[['is sexual predator']]))\n",
    "eclf_prediction = eclf.predict(test[features])\n",
    "\n",
    "\n",
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], eclf_prediction) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], eclf_prediction)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], eclf_prediction)\n",
    "print 'F1:', met.fbeta_score(test[['is sexual predator']], eclf_prediction, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'lr__C': [1.0, 100.0], 'rf__n_estimators': [20, 200],}\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "grid = grid.fit(iris.data, iris.target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
