{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extracting_Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU1LcR5aIT-M",
        "colab_type": "text"
      },
      "source": [
        "## Extracting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaoHiFdZIRNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb6e6d8b-884e-43c5-c059-f8f0618a00ce"
      },
      "source": [
        "cd drive/My\\ Drive/sih_project"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/sih_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIDVsIyNIr-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e90145a-805b-428c-a4c8-94f1479d71f7"
      },
      "source": [
        "ls "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mextracted_files\u001b[0m/  \u001b[01;34mpkg_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Y16udiIygl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b779a31c-8e49-421d-e218-2d96659ad1c4"
      },
      "source": [
        "!mkdir extracted_files\n",
        "!unzip -q pkg_data/pan12-sexual-predator-identification-test-corpus-2012-05-21.zip -d extracted_files/\n",
        "!unzip -q pkg_data/pan12-sexual-predator-identification-training-corpus-2012-05-01.zip -d extracted_files/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘extracted_files’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2noUib22LF2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv extracted_files/pan12-sexual-predator-identification-test-corpus-2012-05-21/ extracted_files/test_corpus\n",
        "!mv extracted_files/pan12-sexual-predator-identification-training-corpus-2012-05-01/ extracted_files/train_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "povOgLBKK4oI",
        "colab_type": "text"
      },
      "source": [
        "## Extracting Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJXOSCLOKTCV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "104c2b12-4383-46cf-cb19-8c0ee9599d14"
      },
      "source": [
        "!cat extracted_files/train_corpus/readme.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========\n",
            "Overview\n",
            "========\n",
            "\n",
            "This archive contains the training corpus for the \"Sexual Predator Identification\" task of the PAN 2012 Lab, held in conjunction with the CLEF 2012 conference.\n",
            "\n",
            "Find out about all the details at http://pan.webis.de.\n",
            "\n",
            "\n",
            "\n",
            "===========================\n",
            "Training Corpus Description\n",
            "===========================\n",
            "\n",
            "Update 01 May 2012:\n",
            "\n",
            "pan12-sexual-predator-identification-training-corpus-2012-05-01.xml A new xml file containing conversations without bad username substitution.\n",
            "pan12-sexual-predator-identification-diff.txt A text file containing conversation id and line number of modified text \n",
            "pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt The list of predators without the ones not present in the traininig set\n",
            "\n",
            "\n",
            "\n",
            "The corpus comprises:\n",
            "\n",
            "pan12-sexual-predator-identification-training-corpus.xml An xml file containing around 60000 documents (each document is a conversation)\n",
            "pan12-sexual-predator-identification-training-corpus-predators.txt A file containing a list of predators id\n",
            "\n",
            "The xml file is organized as follow:\n",
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<conversations>\n",
            "  <conversation id=\"id_of_the_conversation\">\n",
            "    <message line=\"1\">\n",
            "      <author>author_1_id</author>\n",
            "      <time>02:56</time>\n",
            "      <text>Bla bla bla bla</text>\n",
            "    </message>\n",
            "    <message line=\"2\">\n",
            "      <author>author_2_id</author>\n",
            "      <time>02:56</time>\n",
            "      <text>bla bla</text>\n",
            "    </message>\n",
            "[...]\n",
            "    <message line=\"n\">\n",
            "      <author> author_1_id </author>\n",
            "      <time>07:12</time>\n",
            "      <text>bla bla bla</text>\n",
            "    </message>\n",
            "  </conversation>\n",
            "</conversations>\n",
            "\n",
            "Every conversation, identified by and unique id, contains a set of messages. Each message, identified by a line number unique in the conversation, is produced by an author, identified by the author_id. In each message there is the text produced by the user and a time indication.\n",
            "\n",
            "Please note that time, user_id and email address have been processed as follows: \n",
            "- The time is formatted as hours:minutes (might not be the real time)\n",
            "- The user_id replaces any mentioning of the user within the conversation\n",
            "- The email addresses have been replaced with a tag <email/>\n",
            "\n",
            "Despite the preprocessing performed on the documents contained in the dataset, we are not responsible for the content of the documents (e.g eventual personal informations that might be contained in the text).\n",
            "\n",
            "The training is a representative sample of the testing dataset and should be considered a training in the sense of \"practicing\" set. \n",
            "\n",
            "The .txt file contains a list of user_id who are Sexual Predator.\n",
            "\n",
            "Given the public nature of the dataset, we ask the participants not to use external or online resources for resolving this task (e.g. search engines) but to extract evidence from the provided datasets only. \n",
            "\n",
            "\n",
            "==========\n",
            "Contacts\n",
            "==========\n",
            "\n",
            "In case of problem with the corpus, you can write directly to Giacomo Inches at giacomo.inches@usi.ch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQRGDn7rPPgC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "9df95e9c-41ae-4935-c9f4-fdd611722046"
      },
      "source": [
        "!ls extracted_files/train_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pan12-sexual-predator-identification-diff.txt\n",
            "pan12-sexual-predator-identification-training-corpus-2012-05-01.xml\n",
            "pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt\n",
            "readme.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeNemzS_LyoK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a450ebd0-77de-4b94-f662-ed55d9285473"
      },
      "source": [
        "train_predators = []\n",
        "with open('extracted_files/train_corpus/pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt', 'r') as f:\n",
        "    train_predators = f.readlines()\n",
        "print(\"Total number of predators in Training corpus : {}\".format(len(train_predators)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of predators in Training corpus : 142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5YduZtOPLC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.system('pip install xmltodict')\n",
        "import xmltodict\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "class ExtractText():\n",
        "    def __init__(self, filename, out_folder='./'):\n",
        "        '''\n",
        "        Extract details from XML files\n",
        "        Args : filename -> Path to the XML file\n",
        "               out_folder -> Path to output folder\n",
        "        '''\n",
        "        self.filename = filename\n",
        "        if (out_folder[-1]=='/'):\n",
        "            self.out_folder = out_folder\n",
        "        else:\n",
        "            self.out_folder = out_folder + '/'\n",
        "        \n",
        "        try:\n",
        "            os.mkdir(self.out_folder)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        print(\"Parsing XML to Dictionary...\")\n",
        "        dictionary = self.xml_to_dictionary()\n",
        "\n",
        "        # Converting chat message with single chat to list format\n",
        "        for i in dictionary['conversations']['conversation']:\n",
        "            if (str(type(i['message'])) != \"<class 'list'>\"):\n",
        "                i['message'] = [i['message']]\n",
        "\n",
        "        print('Converting XML to JSON format...')\n",
        "        self.xml_to_json(dictionary)\n",
        "\n",
        "        print('Converting XML to CSV format...')\n",
        "        self.xml_to_csv(dictionary)\n",
        "        print(\"Files created in {} directory\".format(self.out_folder))\n",
        "\n",
        "    def xml_to_dictionary(self):\n",
        "        '''\n",
        "        Converts XML file to data dictionary\n",
        "        '''\n",
        "        with open(self.filename) as xml_file:\n",
        "            data_dict = xmltodict.parse(xml_file.read())\n",
        "        return data_dict\n",
        "\n",
        "    def xml_to_json(self, dictionary):\n",
        "        '''\n",
        "        Converts parsed dictionary to json and saves\n",
        "        '''\n",
        "        data = json.dumps(dictionary)\n",
        "        with open(self.out_folder + self.filename.split('/')[-1].rstrip('xml') + 'json', 'w') as f:\n",
        "            f.write(data)\n",
        "\n",
        "    def xml_to_csv(self, dictionary):\n",
        "        '''\n",
        "        Converts parsed dictionary to dataframe and saves in CSV format\n",
        "        '''\n",
        "        data = []\n",
        "        for conv in dictionary['conversations']['conversation']:\n",
        "            id = conv['@id']\n",
        "            for message in conv['message']:\n",
        "                d = dict()\n",
        "                d = {key: message[key] for key in message.keys()}\n",
        "                d['@id'] = id\n",
        "                data.append(d)\n",
        "        df = pd.DataFrame(data)\n",
        "        df.to_csv(self.out_folder + self.filename.split('/')[-1].rstrip('xml') + 'csv')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SloxYRm9oxEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "addf2cac-d385-4674-842e-20de3d6851c9"
      },
      "source": [
        "ExtractText('extracted_files/train_corpus/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml', 'data')\n",
        "ExtractText('extracted_files/test_corpus/pan12-sexual-predator-identification-test-corpus-2012-05-17.xml', 'data')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing XML to Dictionary...\n",
            "Converting XML to JSON format...\n",
            "Converting XML to CSV format...\n",
            "Files created in data/ directory\n",
            "Parsing XML to Dictionary...\n",
            "Converting XML to JSON format...\n",
            "Converting XML to CSV format...\n",
            "Files created in data/ directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ExtractText at 0x7f9221d76630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    }
  ]
}